[["index.html", "Bioinformatics Notes  Chapter 1 Introduction", " Bioinformatics Notes  Chapter 1 Introduction The state of technology in bioinformatics is frantically moving forward. Datasets are growing exponentially. Based on recent data: ‚ÄúOver 2.5 quintillion bytes of data are created every single day, and it‚Äôs only going to grow from there. By 2020, it‚Äôs estimated that 1.7MB of data will be created every second for every person on earth.‚Äù. A large amount of this data, is medical and clinicians, familiar with the traditional statistical methods, are at a loss to analyse them. Traditional methods have difficulty in identifying outliers and finding patterns. Machine Learning is able to cover these limitations. Up till the last decade, medical professionals have been reluctant to use machine learning (I‚Äôm not in a position to have any assumptions as to why üòä). Although with my perspective, adequate health care will soon become highly dependent on modern machine learning capabilities. We already saw a huge push towards this adoption due to the Corona Virus pandemic. AI software solutions will take over repetitive and simple tasks. History teaches us that the arrival of new technology tends to increase, rather than reduce, the need for human personnel. The most common analogy is that AI will help a radiologist (for example) like a GPS guides the driver of a car. AI will offer proposals to the radiologists and help the doctor to make a better and more accurate diagnosis. But it will be the doctor who ultimately decides. Today, more than 60 years after the birth of ‚ÄúAI‚Äù, the field has continued to grow and to evolve in many directions. Significant breakthroughs in AI have occured as the result of ongoing advances in data collection and aggregation, processing power, deep learning algorithms, and convolutional neural networks. Some of the most promising applications of AI have been in image processing and image analysis. In just a few short years, AI applications in radiology have ‚Äúexploded‚Äù and AI has become big business üí∏. This has largely been due to the progress in artificial neural networks, the increasing rise of cloud computing, and the increased interest of medical professionals to pursue research in this amazing field. Identifying and characterizing lung nodules on CT scans, computer-aided diagnosis of breast cancer on mammographic films, and automatic calculation of bone age by computer software on plain X-ray films of the hand are among the first such applications. Advanced segmentation techniques have opened up new avenues. Today, in diseases such as multiple sclerosis, Alzheimer‚Äôs dementia, and traumatic brain injuries, AI is transforming patient care through accurate volume measurements of lesions and brain structures. Nowadays, we‚Äôre pretty confident that AI can be used to diagnose common neurological diseases with an accuracy rate close to 90%, comparable to that of a experienced senior doctor. What seemed to be huge experiments are nothing but mere proof‚Äôs of concepts now. We started out with the 10k SNP chip and now we have 3 million SNP arrays. We‚Äôre talking about 30 billion nucleotide reads per sample. Such computations obviously take place on computers and there‚Äôs a huge need of efficient algorithms to make sense of such amounts of data. We have a lot of publicly available tools which aim to tackle very specific problems and are mostly not ideal for automated processes. In the recent years the statistical programming language R has become increasingly popular in genomic data analysis (some might even argue it‚Äôs the de facto standard). If you want a primer on R kindly visit Chapter 1 which briefly covers the language (not exhaustive) "],["basics.html", "Chapter 2 Basics of R 2.1 Why R ? ü§∑Ô∏è 2.2 Installing R üóº 2.3 Basic Syntax", " Chapter 2 Basics of R 2.1 Why R ? ü§∑Ô∏è R is a software environment and programming language for statistical analysis. Originally written by Robert Gentleman and Ross Ihaka from the University of Auckland. Currently it‚Äôs developed by the R Development Core Team. As highlighted in the Introduction, in the recent years R has become the de facto standard for many statisticians (Even this book is written in R markdown). R is free to use and open source(released under the GNU public license). It‚Äôs platform independent (Windows, MacOS, and Linux distributions are supported). R consists of a base installation and can be extended through packages to tackle a wide range of problems. There are tons of packages freely available for data analysis in R. From importing a wide range of data formats, pre-processing data, control tests, downstream integration and any other part of the pipeline. Although truth be told the learning curve for R is pretty steep üìà. R is case-sensitive and there‚Äôs a lack of well-established naming conventions. R is not really memory efficient and because of the fact that it‚Äôs a scripted language it‚Äôs slow compared to other compiler based languages. 2.2 Installing R üóº R can be downloaded from here. Just go through the basic setup process and come back once done. Also install R-Studio, this makes it easy to install packages and handle source control software like git. R-Studio has the R-Console as well so don‚Äôt worry about multiple windows. 2.3 Basic Syntax The R-Console is a really simple interface. &gt; + The &gt; symbol simply means that you can give commands to the console and the + symbol at the start means that it‚Äôs a continuation from the previous line. To assign or allocate values to a variable you should use the &lt;- operator. For example, a &lt;- 5 Assigns the value 5 to the variable a. If you type a on the console, the output is going to be like: &gt; a [1] 5 Most of the times, you‚Äôll use scripts rather than typing commands in the terminal. Scripts allows us to use all the basic features of programming languages like modularity, efficiency and repeatability. Many times, we‚Äôll need to check our current path / working directory (The current folder in which we‚Äôre in). For that we can use the getwd() command in the console. Alternatively, we can change the working directory using the setwd(\"path\") command. "],["genomics.html", "Chapter 3 Genomics  3.1 Basics of Genomics  3.2 Genetic Markers üñä", " Chapter 3 Genomics  3.1 Basics of Genomics  3.1.1 Transcription Genetic Information can be: Genomic (concerning the DNA) Transcriptomic (concerning the transcriptome RNA) Gene expression is the process by which a product such as a protein or RNA is created by a gene. Transcription is the process of producing the transcriptome from the genome. DNA contains all the information necessary to create new macromolecules such as proteins and beyond human beings. DNA encodes the data representing the blueprint of a particular person. The process by which a DNA is transcribed into corresponding RNA proceeds through a series of steps. Initiation ‚Üí DNA macromolecule opens and an enzyme (RNA polymerase) binds with the promoter of the template strand Elongation ‚Üí RNA polymerase processes each nucleotide on the DNA template strand to produce mRNA Termination ‚Üí Transcription stops either when meeting a ‚ÄúRho‚Äù protein factor or a loop at the end of the DNA strand Processing ‚Üí Newly created mRNA macromolecule is processed by removing the introns and slicing the exons together so that only regions coding for proteins are maintained. During this process, mRNA nucleotides are synthesized following a very strict process: DNA A ‚Üí mRNA U DNA T ‚Üí mRNA A DNA C ‚Üí mRNA G DNA G ‚Üí mRNA C 3.1.2 Translation Translation is the process of producing a protein from a messenger RNA. Proteins are made up of amino aicds. Each amino acid is coded by three nucleotides in the mRNA. The sequence of aminoacids composing a protein is synthesized by one by one and glued together as the translation progresses, in the order dictated by the strand. This process takes place in ribosomes, organelles located in the cytoplasm where the mRNA has been led after the transcription. A ribosoome reads the mRNA strand in groups of three bases to assemble the protein. There are 20 aminoacids in humans. A certain combination of 3 bases, also called a codon, always leads to the same aminoacid. There are 64 codons, out of which 61 code for aminoacids, plus 3 stop codons. Most aminoacids are therefore coded by several different codons 3.2 Genetic Markers üñä In this section, we‚Äôll learn about genetic markers and their use in association studies. 3.2.1 What are Markers ? ü§∑Ô∏è Genetic markers can be described as measurable variation (polymorphism) at the DNA level. They are chromosome regions where differences in nucleotide sequences occur between individuals of the same species. Various types of markers have been used to detect DNA variability, some of the most common ones are: Restriction fragment length polymorphism (RFLP) Random amplification of polymorphic DNA (RAPD) Amplified fragment length polymorphism (AFLP) Single stranded conformation polymorphism (SSCP) Copy number variation (CNV) Microsatellites Single nucleotide polymorphism (SNP) Although, microsatellites and SNP are the most commonly used markers. NOTE: Their is a difference between a genetic marker and DNA variation. A marker is more related to the technique employed to measure the variation whilst DNA variation is obviously independent of our ability to measure it or not. When we talk about DNA variation, we should think more in terms of: indels - insertions or deletions of various lengths VNTRs - variable number of tandem repeats (multiple copies of the same sequence of DNA, usually simple non-coding repeats) SNP - single nucleotide polymorphisms which are a single nucleotide mutations (base mutations). 3.2.2 What is an Association Study ? The objective of an association study is to link a specific DNA region (and it‚Äôs underlying variation) with a trait of interest. For example in human research, many studies have been undertaken to identify genomic regions which confer greater resistance/susceptibility to diseases such as cancer, and ultimately, within these regions, identify the variants that lead to expression of the trait. Knowledge of such functional variations improves our understanding of disease mechanisms, suggests target for novel therapeutics and can be useful for risk prediction and prevention. Identification of regions associated with a trait can also help select candidate regions for gene discovery - i.e, identify the actual genes and the functional mutations that confer the trait differences. NOTE that an association does not imply causality. A marker can be associated with a trait but it is not necessarily in any way related to it. A Chromosome is a physical structure of nucleotides connected to each other which only get broken up by recombination events. Hence, we can think of DNA sequences being transmitted from parent to offspring in chunks. The closer the marker is to the actual causative gene, the greater the chance that the same marker allele will be transmitted to the offspring with the same causative allelic variant. Thus, the marker and the gene are in linkage on the same DNA chunk, or formally haplotype . A haplotype is a chunk of DNA which has a combination of alleles that would not be observed by chance if each one was segregating independently. This leads us to the concept of linkage disequilibrium (LD): a non-random association of alleles. A linkage is like the actual physical connection of nucleotides on a DNA strand. Whereas, linkage disequilibrium is a statistical test of significance, but it‚Äôs not necessarily telling us anything about the actual physical proximity of what we‚Äôre testing. 3.2.3 Microsatellites üõ∞ Microsatellites are a type of VNTR (variable number of tandem repeats). If the length of the repeating unit is less than five base pairs, the VNTR is referred to as a microsatellite. If the length of the repeating unit is greater than five base pairs the VNTR is called a minisatellite. Variation in microsatellites is measured through the number of repeats that an individual has of the recording unit. We can get a handle on microsatellites using PCR(polymerase chain reaction) methods. Basically, we amplify regions that have the repeating sequence and seperate them by virtue of their size. We can refer to these different sizes as an allele. As discussed marker alleles are not necessarily causative of the trait. In the case of microsatellites it‚Äôs almost a given that they are not causative and that they are in non-coding regions. Microsatellites can have upto 10 to 30 different alleles (SNP‚Äôs generally have 2). A single microsatellite marker can be more informative than a SNP but they are generally more sparse with much lower LD between marker and the causal variant. "],["systems-biology.html", "Chapter 4 Systems Biology 4.1 Molecules to Pathways", " Chapter 4 Systems Biology Systems Biology is the computational and mathematical analysis and modeling of complex biological systems. Basic Terminology:- Genome: A set of chromosomes. Genomics: An interdisciplinary field focusing on the structure, function, evolution, mapping and editing of genomes. Epigenomics: Study of genomic modifications. Transcription: Regulation of gene expression and patterns of mRNA expression. Omics: An approach most often experimental that measures many individual entities that make up a system. Proteomics: Study of many proteins at a time. Metabolomics: Study of many metabolities in an organism/tissue/cell. Dynamic Modeling: Based on differential equations to quantitatively estimate how pathways react to stimuli 4.1 Molecules to Pathways 4.1.1 cAMP Pathway cAMP stands for Cyclic Adenosine Monophosphate and was discovered by Earl Sutherland and Ted Rall. It‚Äôs a G protein coupled receptor (GPCR) triggered signalling cascade (a series of events through which stimuli is transmitted). The \\(G_s\\) alpha sub-unit protein is activated in a cAMP pathway. cAMP leads to the activation of an enzyme called protein kinase A (PKA). PKA is called as a cAMP-dependent enzyme because it gets activated only if cAMP is present. PKA activation leads to:- It phosphorylates enzymes that convert glycogen into glucose. It phosphorylates enzymes that promote cardiac contraction. It phosphorylates enzymes that regulate gene expression. Conversion of information from outside the cell which is not recognised outside the cell, to a form that can be recognised inside the cell is known as the Transduction process. "],["statistics-in-medicine.html", "Chapter 5 Statistics and Machine Learning in Medicine 5.1 Samples vs Population 5.2 Study Design 5.3 Data Types 5.4 Linear Regression 5.5 Logistic Regression", " Chapter 5 Statistics and Machine Learning in Medicine 5.1 Samples vs Population If we take samples instead of the whole population we‚Äôll have to learn to contend with that fact that there will be a error in estimate because we‚Äôre observing a subset rather than the whole population. For studies it is optimal if the sample which provides the data is representative of the population under study. 5.1.1 Simple Random Sampling A scheme in which every possible subsample of size \\(n\\) from a population is equally likely to be selected. This Sampling might accidentally develop biases that‚Äôs why it isn‚Äôt preferred in practice. 5.2 Study Design 5.2.1 Prospective Cohort Studies In both of the following cases subjects are classified according to their exposure status when the study starts and then followed over time to see who develops outcome(s) :- 5.2.1.1 Randomized / Controlled Study Design Get a representative sample from the population Randomly assign to exposure groups This study design has some benefits :- Helps protect against self-selection biases Eliminates systematic differences in characteristics 5.2.1.2 Observational (Cohort) Studies Get a sample from the population and then ascertain group membership Get samples from different populations to be compared ConFounders: confounders are factors that are related both to the outcome and the exposure of interest and are a challenge to analysing such observational studies. 5.2.2 Case / Control Studies Subjects are chosen based on their outcome status, and the exposure(s) that occured prior to outcome are assessed. Usually done for rare outcomes because if we were to use a prospective cohort study we‚Äôd have to make a huge popultaiion to get any outcome. 5.3 Data Types 5.3.1 Continuous Data Defining characteristic: One unit change in value means the same thing across the entire range of values 5.3.2 Categorical Data Where only a discrete set of values are possbile. 5.3.2.1 Types Nominal Categorical Data: No inherent order to categories Ordinal Categorical Data: order to categories Binary Data (It‚Äôs a special type): Takes only two values (Yes / No) 5.3.3 Time-to-Event Data Count data collected over a period of time Data which is hybrid of continuous and binary data. 5.4 Linear Regression 5.4.1 Basic Terminology Basic Structure : (Some function of an outcome) = intercept + (slope)*(x) \\(f(y) = \\beta_o + \\beta_1x_1\\) Here, x is a predictor of interest. (can be continuous , binary or categorical) LHS depends on what variable type the outcome of interest is: For continuous outcomes, LHS is the mean of the outcome For Binary outcomes, LHS is the \\(ln(odds)\\) of the binary outcome , i.e. \\(ln(\\frac{p}{1-p})\\), where p is the probability that y = 1 For time-to-event outcomes: Where the individual event and censoring times are not known, y is yes/no indicator, the LHS is ln(incidence rate) and the regression type is Poisson regression Where the individual event and censoring times are known, the LHS is ln(hazard rate) and the regression type is Cox regression The beauty of regression is that it allows for continuous predictors 5.4.2 Simple Linear Regression with a Binary Predictor The equation in this case is: \\(\\bar{y} = \\beta_0 + \\beta_1x_1\\) We will only be able to estimate the regression equation from a sample of data To indicate estimates we use : \\(\\bar{y} = \\hat{\\beta_0} + \\hat{\\beta_1}x_1\\) or more frequently as \\(\\hat{y} = \\hat{\\beta_0} + \\hat{\\beta_1}x_1\\) The slope compares the mean value of y for two groups who differe by one unit of \\(x_1\\)and is interpretable as a mean difference Example: Data on anthropometric measure from a random sample of 150 Nepali children 0-12 months To find ‚Üí Relation Between arm circumference(y) and sex of a child(x) Let x = 0 for male and x = 1 for female For female children : \\(\\hat{y} = \\hat{\\beta_0} + \\hat{\\beta_1}(1)\\) For male children : \\(\\hat{y} = \\hat{\\beta_0}\\) The slope \\(\\hat{\\beta_1}\\) estimates the mean difference in arm circumference for female children compared to male children. 5.4.3 Simple Linear Regression with a Categorical Predictor Sometimes, regression scenarios includes predictors which are multi-categorical. Ex: Data were collected in 800 US academic physicians, including yearly salary. Additional information was also collected including geographical region of the US (West, Northeast, South, Midwest) To find ‚Üí Do average salaries differ by geographical region ?? Approach 1 !! : Arbitrarily give each region a numerical ****value. Why this is Stupid: Coding is arbitrary The value of \\(\\hat{\\beta_1}\\) will depend on the scheme of coding, the results will not be equivalent for different schema Coding ‚Äúassumes‚Äù mean salary differences between regions is ‚Äúincremental‚Äù Approach 2 : The preferred approach, deisgnate one region as ‚Äúreference region‚Äù, and make binary indicators for each of the other three. Example : Reference ‚Üí West \\(x_1\\) = 1 if Midwest , 0 otherwise \\(x_2\\) = 1 if South, 0 otherwise \\(x_3\\) = 1 if Northeast, 0 otherwise The Equation is : \\(\\hat{y} = \\hat{\\beta_0} + \\hat{\\beta_1}x_1 + \\hat{\\beta_2}x_2 + \\hat{\\beta_3}x_3\\) Here, each of the 3 slopes, estimates mean salary difference between a region that has a corresponding x value of 1 and the reference region. The intercept, is the estimated mean salary for physicians from the West. For physicians from the Midwest: \\(\\hat{y} = \\hat{\\beta_0} + \\hat{\\beta_1}\\) For physicians from the South: \\(\\hat{y} = \\hat{\\beta_0} + \\hat{\\beta_2}\\) For physicians from the Northeast: \\(\\hat{y} = \\hat{\\beta_0} + \\hat{\\beta_3}\\) 5.4.4 Simple Linear Regression with a Continuous Predictor Example : Data on anthropometric measures from a random sample of 150 Nepali children 0-12 months old Question ‚Üí Relationship between average arm circumference and height ?? Approach 1: Dichotomize height at median, more than median ‚Üí 1 less ‚Üí 0, then use SLR Cons: Throws away a lot of info in height data Only allows for single comparison Approach 2: Categorize into four categories on the basis of quartile Cons: Still throws away info Requires multiple summary measures Approach 3: Use a computer to estimate a line where our predictor is the height (continuous) Interpretation : Slope is the average change in arm circumference for a 1 unit increase in height Slope is the mean difference in arm circumference for two groups who differ by 1 unit in height Although the intercept has no interpretation, it‚Äôs still important and necessary to fully satisfy the regression line. 5.4.5 Estimating the Regression Equation The main idea is to find a line that is ‚Äúclosest‚Äù to all the points in the given sample. For estimation we can use any error/loss function like Least Squares, categorical crossentropy, ‚Ä¶. Residuals: The distances between observed y-value and the estimated mean. We need to minimize the total sum of the loss for each observations in the sample. 5.4.6 Measuring the Strength of a Linear Association The slope of a regression line estimates the magnitude and direction of the relationship between y and x. But doesn‚Äôt impart any info about how well the line fits the data in the sample The value of regression slope depends on the units of both y and the predictors of interest. The coefficient of determination \\(R^2\\) can also be determined by using linear regression. It varies from 0 to 1, with larger values indicating a ‚Äúcloser fit‚Äù. It measures strength of association by comparing variability of points around the line to variability in y-values ingnoring x. 5.5 Logistic Regression 5.5.1 Overview Logistic Regression is a method for relating a binary outcome to a single predictor that can be binary, categorical or continuous Equation: \\(ln(odds\\,that\\, y=1) = ln(\\frac{p}{1-p}) = \\hat\\beta_0 + \\hat\\beta_1x_1\\) where p is the probability that y = 1. For any given value of x, this equation can be used to estimate \\(ln(odds)\\) of a binary outcome y, for a group of subjects with the same value of x 5.5.1.1 Interpretation Intercept: \\(\\hat\\beta_0\\) is the estimated \\(ln(odds\\, that \\, y = 1)\\) when x = 0 Slope: \\(\\hat\\beta_1\\) is the change in that \\(ln(odds\\, that \\, y = 1)\\) for a one-unit change in x OR the difference in the \\(ln(odds\\, that \\, y = 1)\\) for a one-unit difference in x. This difference in \\(ln(odds)\\) is the natural log of an odds ratio 5.5.2 Estimation For logistic Regression, we use ‚Äúmaximum likelihood‚Äù, this must be done with a computer as it just does hit-and-trial and finds the best possible values. 5.5.3 Estimating Risk and Risk Functions Can only be done if the study allows for risk estimates \\(odds = \\frac{\\hat p}{1 - \\hat p} \\implies \\hat p = \\frac{odds}{1+odds} \\implies \\hat p = \\frac{e^{ln(odds)}}{1+e^{ln(odds)}}\\) "]]
