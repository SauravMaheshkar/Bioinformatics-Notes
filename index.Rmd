--- 
title: "Bioinformatics Notes ðŸ§¬"
site: bookdown::bookdown_site
documentclass: book
bibliography: [book.bib, packages.bib]
biblio-style: apalike
link-citations: yes
description: "A R Bookdown ðŸ“– Project containing my notes on Bioinformatics ðŸ¦  and Genomics ðŸ§¬"
---

# Introduction {#intro}

The state of technology in bioinformatics is frantically moving forward. Datasets are growing exponentially. Based on recent data:

> "Over 2.5 quintillion bytes of data are created every single day, and it's only going to grow from there. By 2020, it's estimated that 1.7MB of data will be created every second for every person on earth.".

A large amount of this data, is medical and clinicians, familiar with the traditional statistical methods, are at a loss to analyse them. Traditional methods have difficulty in identifying outliers and finding patterns. Machine Learning is able to cover these limitations. 

Up till the last decade, medical professionals have been reluctant to use machine learning (I'm not in a position to have any assumptions as to why ðŸ˜Š). Although with my perspective, adequate health care will soon become highly dependent on modern machine learning capabilities. We already saw a huge push towards this adoption due to the Corona Virus pandemic. AI software solutions will take over repetitive and simple tasks. History teaches us that the arrival of new technology tends to increase, rather than reduce, the need for human personnel. **The most common analogy is that AI will help a radiologist (for example) like a GPS guides the driver of a car**. AI will offer proposals to the radiologists and help the doctor to make a better and more accurate diagnosis. But it will be the doctor who ultimately decides. 

Today, more than 60 years after the birth of "AI", the field has continued to grow and to evolve in many directions. Significant breakthroughs in AI have occured as the result of ongoing advances in data collection and aggregation, processing power, deep learning algorithms, and convolutional neural networks. Some of the  most promising applications of AI have been in image processing and image analysis. In just a few short years, AI applications in radiology have "**exploded**ðŸ¤¯" and AI has become big business ðŸ’¸. This has largely been due to the progress in artificial neural networks, the increasing rise of cloud computing, and the increased interest of medical professionals to pursue research in this amazing field.

Identifying and characterizing lung nodules on CT scans, computer-aided diagnosis of breast cancer on mammographic films, and automatic calculation of bone age by computer software on plain X-ray films of the hand are among the first such applications. Advanced segmentation techniques have opened up new avenues. Today, in diseases such as multiple sclerosis, Alzheimerâ€™s dementia, and traumatic brain injuries, AI is transforming patient care through accurate volume measurements of lesions and brain structures. Nowadays, we're pretty confident that AI can be used to diagnose common neurological diseases with an accuracy rate close to 90%, comparable to that of a experienced senior doctor. 

What seemed to be huge experiments are nothing but mere proof's of concepts now. 

We started out with the 10k SNP chip and now we have 3 million SNP arrays. We're talking about 30 billion nucleotide reads per sample. Such computations obviously take place on computers and there's a huge need of efficient algorithms to make sense of such amounts of data. 

We have a lot of publicly available tools which aim to tackle very **specific** problems and are mostly not ideal for automated processes. In the recent years the statistical programming language **R** has become increasingly popular in genomic data analysis (some might even argue it's the *de facto* standard). If you want a primer on R kindly visit Chapter 1 which briefly covers the language (not exhaustive)
